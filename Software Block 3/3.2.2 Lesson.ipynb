{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "H-zhrR2UeZ1m"
      },
      "source": [
        "# **3.2.2 Lesson**\n",
        "\n",
        "The purpose of this notebook is to familiarize yourself on the basics of machine learning, and how to use relevant libraries in Python.\n",
        "\n",
        "After this exercise, you should be able to load and manipulate data, and create a basic model that you can use to solve simple regression and classification problems\n",
        "\n",
        "For our purposes, we do not expect you to understand the mathematical background of many of these topics, but expect to gradually understand **WHAT** certain functions, models, and optimizers are, **HOW** to use them, and **WHY** we use them.\n",
        "\n",
        "**At the end of this assignment, you will deliver:**\n",
        "1. **A working (hopefully) classification model that is very good at distinguishing between images of clothing**\n",
        "2. **Questions to share**\n",
        "3. **Some insight to give at the next meeting**"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "TcJQrPPggSPR"
      },
      "source": [
        "## **Intro to ML using Pytorch**"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "wqwbFAGSe9Rz"
      },
      "source": [
        "When it comes to machine learning, there are two major types of problems we deal with: **regression** and **classification**\n",
        "\n",
        "- **Classification**: for a new picture (data point), what **class** does it belong in out of a finite number of **classes**?\n",
        "  - Example: given a new picture of an animal, does it belong in the **fish class**, the **dog class**, or the **cat class**?\n",
        "- **Regression**: for a new personal profile (data point), what is its predicted output value? (Think of regression as a classification problem with an *infinite* number of classes)\n",
        "  - Example: say a person is 30 years old, has 25,000 dollars in student loans, three kids, two cars, and a $83,000 salary. What is their predicted credit score?"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "da1cYBZoKko-"
      },
      "source": [
        "In most pytorch pipelines, there are three major steps to consider:\n",
        "\n",
        "1. Design the model -- input size, output size, forward pass\n",
        "2. Create loss and optimizer functions\n",
        "3. Implement the training loop:\n",
        "  - in the forward pass, compute the prediction and loss\n",
        "  - in the backward pass analyze the gradients\n",
        "  - from the analysis, update the weights\n",
        "\n",
        "Note that this is basically all done for you in the PyTorch package, all you need to understand the the high level organization of these steps"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "U9PxTCBPhZGO"
      },
      "source": [
        "# **EXERCISE: Classification in Pytorch**"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "PHghSN3ovhs4"
      },
      "source": [
        "Now that we have a general framework of how to build a model, we will do the same with a classification problem"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "olU4I8MVqolW"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "HRiIpJ-W-fxo"
      },
      "source": [
        "Here, I am loading the MNIST-Fashion dataset -- this is similar to the MNIST set of handwritten digits, but this is for 10 classes of clothing articles like shoes, trousers, pullovers, etc"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "k8rNzImszbmX"
      },
      "source": [
        "Some important terminology to know:\n",
        "  - a *transform* is a data manipulation framework. There are many things you can do inside a transform, here the transform is waiting to convert data to a *tensor* and *normalize* it\n",
        "    - a *tensor* is a fancy word for a special PyTorch array/matrix, the behavior is the same as regular arrays, but they are optimized for PyTorch\n",
        "    - *normalizing* usually means that we take the values of our data and represent them with equal or random weight. This is to ensure that no one feature has a greater impact on the output than another. Here we need to consider that each pixel is represented on a grayscale, so we want to normalize each pixel according to a gaussian curve with mean and standard deviation 0.5\n",
        "    \n",
        "\n",
        "\n",
        "  - a *data loader* can be seen as an intermediary step in between actually putting your data into your model. Having a dataloader can speed up model processing, and give some cool features like shuffling your data.\n",
        "    - TLDR: loop over the dataloader instead of the data itself, and good things happen :)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7tiwei5uxKY9"
      },
      "outputs": [],
      "source": [
        "# Define a transform to normalize the data\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),  # Convert the image to PyTorch tensor\n",
        "    transforms.Normalize((0.5,), (0.5,))  # Normalize with mean=0.5 and std=0.5\n",
        "])\n",
        "\n",
        "# Load the Fashion-MNIST datasets\n",
        "train_dataset = datasets.FashionMNIST(root='./data', train=True, transform=transform, download=True)\n",
        "test_dataset = datasets.FashionMNIST(root='./data', train=False, transform=transform, download=True)\n",
        "\n",
        "# Create data loaders for training and testing\n",
        "train_loader = DataLoader(dataset=train_dataset, batch_size=64, shuffle=True)\n",
        "test_loader = DataLoader(dataset=test_dataset, batch_size=1000, shuffle=False)\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "MCHsFRxM7T1B"
      },
      "source": [
        "Now lets define our model architecture!\n",
        "\n",
        "We are gonna define a fairly advanced model based on a convolutional neural network (CNN), so take some time to research (use ChatGPT) and understand each part of this. Understanding this part is crucial to what we will be doing moving forward. I will give a high level instruction of what to do, and you can copy and paste each step into ChatGPT to learn more about it, and what to write for that step.\n",
        "\n",
        "I started with the class stem and implementing the forward function, this will be the blank canvas for our model\n",
        "\n",
        "**In the init__ constructor:**\n",
        "1. (*done for you*) add a convolutional 2d layer with 1 input channel, 16 output channels, and a 3x3 kernel\n",
        "2. add a second convolutional 2d layer with 16 input channels, 32 output channels, and a 3x3 kernel\n",
        "3. create a max pooling 2d layer with a 2x2 filter and a kernel size of 2\n",
        "4. create a fully connected Linear layer to flatten an input vector of 32 * 7 * 7 to 128\n",
        "5. create one more fully connected Linear layer that takes an input vector size of 128 and outputs a vector of probabilities of length 10\n",
        "\n",
        "\n",
        "**In the forward pass function**\n",
        "1. (*done for you*) send x through the **first convolutional layer** -> send that through a **torch.relu()** activation function -> **pool** the results\n",
        "2. send x through the **second convolutional layer** -> send that through a **torch.relu()** activation function -> **pool** the results\n",
        "3. flatten x to a single dimension vector using x.view(-1, 32 * 7 * 7)\n",
        "4. send x through the **first fully connected Linear** layer -> send that through a **torch.relu()** activation function\n",
        "5. finally, send x through the **second fully connected Linear** layer.\n",
        "\n",
        "After the last step, we should get a tensor of length 10, each value corresponds to a probability that the input image is that corresponding label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7B03tnYL73o4"
      },
      "outputs": [],
      "source": [
        "class FashionMNIST_CNN(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(FashionMNIST_CNN, self).__init__()\n",
        "\n",
        "    # add layers here -- Replace each \"None\" with the layer code\n",
        "    self.conv1 = nn.Conv2d(1, 16, kernel_size=3, padding=1) # convolutional 2d layer with 1 input channel, 16 output channels, and a 3x3 kernel\n",
        "\n",
        "    self.conv2 = None\n",
        "\n",
        "    self.pool = None\n",
        "\n",
        "    self.fc1 = None\n",
        "\n",
        "    self.fc2 = None\n",
        "\n",
        "  def forward(self, x):\n",
        "\n",
        "    # connect the layers here in the forward pass\n",
        "\n",
        "    # send x through the first convolutional layer\n",
        "    x = self.conv1(x)\n",
        "\n",
        "    # send that through a torch.relu() activation function\n",
        "    x = torch.relu(x)\n",
        "\n",
        "    # pool the results\n",
        "    x = self.pool(x)\n",
        "\n",
        "\n",
        "\n",
        "    # continue here...\n",
        "\n",
        "\n",
        "    return x\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "RqXbmbUzDgEY"
      },
      "source": [
        "Do not worry if you don't know everything that is going on! This is a lot, but the best way to learn is by doing, so lets keep on *doing* and we can tackle actually understanding the model in discussion later!"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "EwEELPYeCjiV"
      },
      "source": [
        "The next thing we have to do is\n",
        "1. Instantiate our CNN model\n",
        "2. Define our loss function (use nn.CrossEntropyLoss())\n",
        "3. Define an optimizer (use optim.Adam()), load the model parameters and set the learning rate to 0.001"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yjhtEFOkFhRL"
      },
      "outputs": [],
      "source": [
        "# instantiate the model\n",
        "\n",
        "# define the loss function/criterion\n",
        "\n",
        "# define the adam optimizer\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "NHuYFLGfFgU-"
      },
      "source": [
        "Now the fun step, we will write the training loop! Be sure to refer back to the example above, but there are a few more things we will add to make this more robust since the MNIST set is much larger and more complex. Here is the pseudocode for the training algorithm\n",
        "\n",
        "1. define a number of epochs (iterations). 5 is a good number for now\n",
        "2. create a training for loop over each epoch\n",
        "  3. set the model to be in training mode using \"model.train()\"\n",
        "  4. set a variable called \"total_running_loss\" for each epoch to 0.0\n",
        "  5. make a nested for loop, this one will iterate over each image and label in the train_loader\n",
        "    6. reset the gradients to zero\n",
        "    7. compute the predicted y (labels) by running the images through the model\n",
        "    8. compute your loss\n",
        "    9. do a backwards pass and compute the gradients on your loss\n",
        "    10. update the weights using the optimizer\n",
        "    11. add the current loss.item() to the total running loss\n",
        "  12. print the total running loss for each epoch to observe progress\n",
        "\n",
        "We should observe that the loss decreases every epoch. Running this loop might take a few minutes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mu-E-jC1GY61"
      },
      "outputs": [],
      "source": [
        "# Write the training loop\n",
        "\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "azDFibyFJyO_"
      },
      "source": [
        "At this point, your model should be fully trained! Here is a function that will evaluate the accuracy of your model using the test set. You may need to change the model name to match what you named your's. Take some time to understand this"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4aMUOGglxnzR",
        "outputId": "537d8af5-672f-4184-ff7c-4ff172403239"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy of the model on the test images: 91.34%\n"
          ]
        }
      ],
      "source": [
        "# Function to evaluate the model\n",
        "def evaluate_model(model, test_loader):\n",
        "    model.eval()  # Set the model to evaluation mode\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    with torch.no_grad():  # Disable gradient calculation for faster inference\n",
        "        for images, labels in test_loader:\n",
        "            outputs = model(images)\n",
        "            _, predicted = torch.max(outputs.data, 1)  # Get the class with the highest score\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    accuracy = 100 * correct / total\n",
        "    print(f'Accuracy of the model on the test images: {accuracy:.2f}%')\n",
        "\n",
        "# Evaluate the model on the test set, CHANGE THE MODEL NAME HERE IF IT IS DIFFERENT\n",
        "evaluate_model(model, test_loader)\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "w3giTe5vLIKl"
      },
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
